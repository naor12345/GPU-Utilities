# CUDA基础
## 代码并行结构
- grid：一个grid分为多个block
- block：一个block分为多个thread
- thread：并行基本单元

## 硬件并行结构
- SMs：多流处理器
- Warp：SMs创建、管理、调度、执行的基本单元。目前每个warp有32个线程，以不同数据执行相同指令。

合并访问：
- 每个warp内的线程对内存要连续访问，避免branch divergence
- 不同warp互相独立

上下文切换：
- CPU线程切换代价较高
- Warp间切换几乎无代价，因为在同一个SMs里，新warp的状态已放入SMs中，硬件资源已分配给thread和block。

一个block内一般不超过1024个thread，同一block驻留在一个SMs上（只由此SMs调度），消耗其共享内存。

等待一个warp执行下一个指令的时间称为 __latency__ ，若调度器总能找到一个warp去执行指令，则称为latency被隐藏。

对于3.x的显卡，一个SMs每次在一个周期内为每个warp发送2个指令，共发送4次。即：每周期8个指令 __=>__ 4个不同的warp，每个给2条指令。

## 内存
### 全局内存
- 地址最分散
- 最影响吞吐量
- 按32-64-128读取，必须对齐

当满足1，2，4，8，16对齐时，可在1个指令周期内直接访问。

### 共享内存
共享内存将被切成大小相同的若干块：bank。

bank conflict：共享内存中，n个寻址将放在n路bank上，可以同时进行；若多个寻址落在一个bank上，则成为bank conflict。此bank上的读取只能串行。

### 纹理内存
使用场合：
- 全局内存或常量内存访问形式不满足时
- 寻址位置从核函数外传入时
- 若需要映射到(0,1)或(-1,1)上时

## 优化
### 提高指令吞吐量
- 使用内部数学函数，降低精度，提高效率
- 避免一个warp内有多个控制流(control divergence)
- \_\_restrict__

### 提高内存吞吐量
- 把更多的host功能用GPU实现，即使它的并行度不高（更低的并行度也比更高的I/O好）
- 一次传输大块内存，而不要多次传输小块内存
- 用页锁定内存

### 异步执行
以下任务可异步执行，具体看显卡的支持：
- 主从并行
- kernel并行
- 传输与kernel并行
- 传输并行
- stream并行

## 其他杂
一个\_\_syncthreads()需要64个周期，旧卡需要128个周期

统一内存访问：必须放在页锁定内存里
- CudaMallocManaged()
- 由于没有cudaMemcpy()，所以需要显式调用cudaDeviceSynchronize()






